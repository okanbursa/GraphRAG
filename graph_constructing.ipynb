{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/okanbursa/GraphRAG/blob/main/graph_constructing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRLtYFyMIXv-"
      },
      "source": [
        "# How to construct knowledge graphs\n",
        "\n",
        "In this guide we'll go over the basic ways of constructing a knowledge graph based on unstructured text. The constructured graph can then be used as knowledge base in a [RAG](/docs/concepts/rag/) application.\n",
        "\n",
        "## ⚠️ Security note ⚠️\n",
        "\n",
        "Constructing knowledge graphs requires executing write access to the database. There are inherent risks in doing this. Make sure that you verify and validate data before importing it. For more on general security best practices, [see here](/docs/security).\n",
        "\n",
        "\n",
        "## Architecture\n",
        "\n",
        "At a high-level, the steps of constructing a knowledge graph from text are:\n",
        "\n",
        "1. **Extracting structured information from text**: Model is used to extract structured graph information from text.\n",
        "2. **Storing into graph database**: Storing the extracted structured graph information into a graph database enables downstream RAG applications\n",
        "\n",
        "## Setup\n",
        "\n",
        "First, get required packages and set environment variables.\n",
        "In this example, we will be using Neo4j graph database."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LA0u0ZeNIXv_",
        "outputId": "6868ac3b-323b-4146-8104-1d07e408b55a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/50.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/209.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.2/209.2 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/301.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.7/301.7 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m59.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m49.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "%pip install --upgrade --quiet  langchain langchain-neo4j langchain-openai langchain-experimental neo4j"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4UoAqts5IXwA"
      },
      "source": [
        "We default to OpenAI models in this guide."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "7tyU98K5IXwA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44a40ede-9246-4cff-edfd-36f45d0aae05"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        }
      ],
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()\n",
        "#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\n",
        "\n",
        "# Uncomment the below to use LangSmith. Not required.\n",
        "# os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass()\n",
        "# os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1OUcV8lIXwA"
      },
      "source": [
        "Next, we need to define Neo4j credentials and connection.\n",
        "Follow [these installation steps](https://neo4j.com/docs/operations-manual/current/installation/) to set up a Neo4j database."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "PyYSm6p-IXwA"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "from langchain_neo4j import Neo4jGraph\n",
        "\n",
        "os.environ[\"NEO4J_URI\"] = \"neo4j+s://41e7e72d.databases.neo4j.io\"\n",
        "os.environ[\"NEO4J_USERNAME\"] = \"neo4j\"\n",
        "os.environ[\"NEO4J_PASSWORD\"] = \"onr3FnCI4vW3CHD9yDKkP5eKM2eyvhI2c6SQPE-wlUI\"\n",
        "\n",
        "\n",
        "graph = Neo4jGraph(refresh_schema=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8lAe0jGAIXwB"
      },
      "source": [
        "## LLM Graph Transformer\n",
        "\n",
        "Extracting graph data from text enables the transformation of unstructured information into structured formats, facilitating deeper insights and more efficient navigation through complex relationships and patterns. The `LLMGraphTransformer` converts text documents into structured graph documents by leveraging a LLM to parse and categorize entities and their relationships. The selection of the LLM model significantly influences the output by determining the accuracy and nuance of the extracted graph data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "7rJ3b2EgIXwB"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(temperature=0, model_name=\"gpt-4-turbo\")\n",
        "\n",
        "llm_transformer = LLMGraphTransformer(llm=llm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKkx7sHRIXwB"
      },
      "source": [
        "Now we can pass in example text and examine the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "-bok5-C4IXwB",
        "outputId": "8f2b9c38-3b43-4219-e79a-3a6cfe780fc4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nodes:[Node(id='Marie Curie', type='Person', properties={}), Node(id='Pierre Curie', type='Person', properties={}), Node(id='University Of Paris', type='Institution', properties={}), Node(id='Nobel Prize', type='Award', properties={})]\n",
            "Relationships:[Relationship(source=Node(id='Marie Curie', type='Person', properties={}), target=Node(id='Nobel Prize', type='Award', properties={}), type='WINNER', properties={}), Relationship(source=Node(id='Marie Curie', type='Person', properties={}), target=Node(id='University Of Paris', type='Institution', properties={}), type='PROFESSOR', properties={}), Relationship(source=Node(id='Pierre Curie', type='Person', properties={}), target=Node(id='Nobel Prize', type='Award', properties={}), type='WINNER', properties={})]\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.documents import Document\n",
        "\n",
        "text = \"\"\"\n",
        "Marie Curie, born in 1867, was a Polish and naturalised-French physicist and chemist who conducted pioneering research on radioactivity.\n",
        "She was the first woman to win a Nobel Prize, the first person to win a Nobel Prize twice, and the only person to win a Nobel Prize in two scientific fields.\n",
        "Her husband, Pierre Curie, was a co-winner of her first Nobel Prize, making them the first-ever married couple to win the Nobel Prize and launching the Curie family legacy of five Nobel Prizes.\n",
        "She was, in 1906, the first woman to become a professor at the University of Paris.\n",
        "\"\"\"\n",
        "documents = [Document(page_content=text)]\n",
        "graph_documents = llm_transformer.convert_to_graph_documents(documents)\n",
        "print(f\"Nodes:{graph_documents[0].nodes}\")\n",
        "print(f\"Relationships:{graph_documents[0].relationships}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xdMJvTkIXwB"
      },
      "source": [
        "Examine the following image to better grasp the structure of the generated knowledge graph.\n",
        "\n",
        "![graph_construction1.png](https://github.com/langchain-ai/langchain/blob/master/docs/static/img/graph_construction1.png?raw=1)\n",
        "\n",
        "Note that the graph construction process is non-deterministic since we are using LLM. Therefore, you might get slightly different results on each execution.\n",
        "\n",
        "Additionally, you have the flexibility to define specific types of nodes and relationships for extraction according to your requirements."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "_oI0F_oZIXwB",
        "outputId": "3dbf44b3-8b3f-4aa3-f658-106dbec98e34",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nodes:[Node(id='Marie Curie', type='Person', properties={}), Node(id='Pierre Curie', type='Person', properties={}), Node(id='University Of Paris', type='Organization', properties={})]\n",
            "Relationships:[Relationship(source=Node(id='Marie Curie', type='Person', properties={}), target=Node(id='Pierre Curie', type='Person', properties={}), type='SPOUSE', properties={}), Relationship(source=Node(id='Marie Curie', type='Person', properties={}), target=Node(id='University Of Paris', type='Organization', properties={}), type='WORKED_AT', properties={})]\n"
          ]
        }
      ],
      "source": [
        "llm_transformer_filtered = LLMGraphTransformer(\n",
        "    llm=llm,\n",
        "    allowed_nodes=[\"Person\", \"Country\", \"Organization\"],\n",
        "    allowed_relationships=[\"NATIONALITY\", \"LOCATED_IN\", \"WORKED_AT\", \"SPOUSE\"],\n",
        ")\n",
        "graph_documents_filtered = llm_transformer_filtered.convert_to_graph_documents(\n",
        "    documents\n",
        ")\n",
        "print(f\"Nodes:{graph_documents_filtered[0].nodes}\")\n",
        "print(f\"Relationships:{graph_documents_filtered[0].relationships}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UIIdbOG7IXwB"
      },
      "source": [
        "To define the graph schema more precisely, consider using a three-tuple approach for relationships. In this approach, each tuple consists of three elements: the source node, the relationship type, and the target node."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ThXfvvcSIXwB",
        "outputId": "923314b1-2555-4690-a799-4a9cef290034",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nodes:[Node(id='Marie Curie', type='Person', properties={}), Node(id='Pierre Curie', type='Person', properties={}), Node(id='Poland', type='Country', properties={}), Node(id='France', type='Country', properties={}), Node(id='University Of Paris', type='Organization', properties={})]\n",
            "Relationships:[Relationship(source=Node(id='Marie Curie', type='Person', properties={}), target=Node(id='Poland', type='Country', properties={}), type='NATIONALITY', properties={}), Relationship(source=Node(id='Marie Curie', type='Person', properties={}), target=Node(id='France', type='Country', properties={}), type='NATIONALITY', properties={}), Relationship(source=Node(id='Marie Curie', type='Person', properties={}), target=Node(id='Pierre Curie', type='Person', properties={}), type='SPOUSE', properties={}), Relationship(source=Node(id='Marie Curie', type='Person', properties={}), target=Node(id='University Of Paris', type='Organization', properties={}), type='WORKED_AT', properties={})]\n"
          ]
        }
      ],
      "source": [
        "allowed_relationships = [\n",
        "    (\"Person\", \"SPOUSE\", \"Person\"),\n",
        "    (\"Person\", \"NATIONALITY\", \"Country\"),\n",
        "    (\"Person\", \"WORKED_AT\", \"Organization\"),\n",
        "]\n",
        "\n",
        "llm_transformer_tuple = LLMGraphTransformer(\n",
        "    llm=llm,\n",
        "    allowed_nodes=[\"Person\", \"Country\", \"Organization\"],\n",
        "    allowed_relationships=allowed_relationships,\n",
        ")\n",
        "graph_documents_filtered = llm_transformer_tuple.convert_to_graph_documents(documents)\n",
        "print(f\"Nodes:{graph_documents_filtered[0].nodes}\")\n",
        "print(f\"Relationships:{graph_documents_filtered[0].relationships}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rASS8fanIXwC"
      },
      "source": [
        "For a better understanding of the generated graph, we can again visualize it.\n",
        "\n",
        "![graph_construction2.png](https://github.com/langchain-ai/langchain/blob/master/docs/static/img/graph_construction2.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3S4NpyMhIXwC"
      },
      "source": [
        "The `node_properties` parameter enables the extraction of node properties, allowing the creation of a more detailed graph.\n",
        "When set to `True`, LLM autonomously identifies and extracts relevant node properties.\n",
        "Conversely, if `node_properties` is defined as a list of strings, the LLM selectively retrieves only the specified properties from the text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "BEUeyV9xIXwC",
        "outputId": "4a14f862-fd2c-43ea-9176-20816db87ba0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nodes:[Node(id='Marie Curie', type='Person', properties={'born_year': '1867'}), Node(id='Pierre Curie', type='Person', properties={}), Node(id='University Of Paris', type='Organization', properties={})]\n",
            "Relationships:[Relationship(source=Node(id='Marie Curie', type='Person', properties={}), target=Node(id='Pierre Curie', type='Person', properties={}), type='SPOUSE', properties={}), Relationship(source=Node(id='Marie Curie', type='Person', properties={}), target=Node(id='University Of Paris', type='Organization', properties={}), type='WORKED_AT', properties={})]\n"
          ]
        }
      ],
      "source": [
        "llm_transformer_props = LLMGraphTransformer(\n",
        "    llm=llm,\n",
        "    allowed_nodes=[\"Person\", \"Country\", \"Organization\"],\n",
        "    allowed_relationships=[\"NATIONALITY\", \"LOCATED_IN\", \"WORKED_AT\", \"SPOUSE\"],\n",
        "    node_properties=[\"born_year\"],\n",
        ")\n",
        "graph_documents_props = llm_transformer_props.convert_to_graph_documents(documents)\n",
        "print(f\"Nodes:{graph_documents_props[0].nodes}\")\n",
        "print(f\"Relationships:{graph_documents_props[0].relationships}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZkRiWP4lIXwC"
      },
      "source": [
        "## Storing to graph database\n",
        "\n",
        "The generated graph documents can be stored to a graph database using the `add_graph_documents` method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "fL6fJIZYIXwC"
      },
      "outputs": [],
      "source": [
        "graph.add_graph_documents(graph_documents_props)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqWXdIJKIXwC"
      },
      "source": [
        "Most graph databases support indexes to optimize data import and retrieval. Since we might not know all the node labels in advance, we can handle this by adding a secondary base label to each node using the `baseEntityLabel` parameter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6rf1gmBZIXwC"
      },
      "outputs": [],
      "source": [
        "graph.add_graph_documents(graph_documents, baseEntityLabel=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9uW409gIXwC"
      },
      "source": [
        "Results will look like:\n",
        "\n",
        "![graph_construction3.png](https://github.com/langchain-ai/langchain/blob/master/docs/static/img/graph_construction3.png?raw=1)\n",
        "\n",
        "The final option is to also import the source documents for the extracted nodes and relationships. This approach lets us track which documents each entity appeared in."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "87yLn7UDIXwC"
      },
      "outputs": [],
      "source": [
        "graph.add_graph_documents(graph_documents, include_source=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nNUe4_JNIXwC"
      },
      "source": [
        "Graph will have the following structure:\n",
        "\n",
        "![graph_construction4.png](https://github.com/langchain-ai/langchain/blob/master/docs/static/img/graph_construction4.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJAHmmjvIXwC"
      },
      "source": [
        "In this visualization, the source document is highlighted in blue, with all entities extracted from it connected by `MENTIONS` relationships."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "wI8FY-B2IXwC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "281e89b1-7140-485d-f405-1fa30b3d7f2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Relationships:[Relationship(source=Node(id='Marie Curie', type='Person', properties={}), target=Node(id='Pierre Curie', type='Person', properties={}), type='SPOUSE', properties={}), Relationship(source=Node(id='Marie Curie', type='Person', properties={}), target=Node(id='University Of Paris', type='Organization', properties={}), type='WORKED_AT', properties={})]\n"
          ]
        }
      ],
      "source": [
        "print(f\"Relationships:{graph_documents_props[0].relationships}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GRAPH RAG EVALUATION"
      ],
      "metadata": {
        "id": "TULcVVpyMwul"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now this code will extract the information from the Psychology Wikipedia page and construct a knowledge graph to test the graph RAG pipeline."
      ],
      "metadata": {
        "id": "Ijsv2A6hNCZD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wikipedia"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FqKu9rMHNVen",
        "outputId": "51c598df-26d4-4497-f4dc-fa2c74f173e1"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wikipedia\n",
            "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from wikipedia) (4.12.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wikipedia) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2024.12.14)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->wikipedia) (2.6)\n",
            "Building wheels for collected packages: wikipedia\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11679 sha256=0093c3c18b6cbbc5d6e471ebf3d7083f510e7950d55f8a38e4d4f4c6bc645ce1\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/b6/c5/93f3dec388ae76edc830cb42901bb0232504dfc0df02fc50de\n",
            "Successfully built wikipedia\n",
            "Installing collected packages: wikipedia\n",
            "Successfully installed wikipedia-1.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import WikipediaLoader\n",
        "from langchain.text_splitter import TokenTextSplitter\n",
        "\n",
        "# Read the wikipedia article\n",
        "raw_documents = WikipediaLoader(query=\"Psychology\").load()\n",
        "# Define chunking strategy\n",
        "text_splitter = TokenTextSplitter(chunk_size=2048, chunk_overlap=24)\n",
        "\n",
        "# Only take the first the raw_documents\n",
        "documents = text_splitter.split_documents(raw_documents[:3])"
      ],
      "metadata": {
        "id": "YQSmQM_gM29A"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm_transformer_query = LLMGraphTransformer(\n",
        "    llm=llm,\n",
        ")"
      ],
      "metadata": {
        "id": "FxB-N8dGO5OS"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph_documents_query = llm_transformer_query.convert_to_graph_documents(documents)\n",
        "print(f\"Nodes:{graph_documents_query[0].nodes}\")\n",
        "print(f\"Relationships:{graph_documents_query[0].relationships}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bRJeNmB4OvdW",
        "outputId": "0e827ae8-708f-4ac2-8d86-348d5c1ddbc3"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nodes:[Node(id='Psychology', type='Discipline', properties={}), Node(id='Mind', type='Concept', properties={}), Node(id='Behavior', type='Concept', properties={}), Node(id='Human', type='Species', properties={}), Node(id='Nonhuman', type='Species', properties={}), Node(id='Conscious Phenomena', type='Concept', properties={}), Node(id='Unconscious Phenomena', type='Concept', properties={}), Node(id='Mental Processes', type='Concept', properties={}), Node(id='Thoughts', type='Concept', properties={}), Node(id='Feelings', type='Concept', properties={}), Node(id='Motives', type='Concept', properties={}), Node(id='Biological Psychologists', type='Group', properties={}), Node(id='Neuroscience', type='Discipline', properties={}), Node(id='Social Scientists', type='Group', properties={}), Node(id='Individual', type='Entity', properties={}), Node(id='Group', type='Entity', properties={}), Node(id='Psychologist', type='Profession', properties={}), Node(id='Behavioral Scientist', type='Profession', properties={}), Node(id='Cognitive Scientist', type='Profession', properties={}), Node(id='Mental Functions', type='Concept', properties={}), Node(id='Social Behavior', type='Concept', properties={}), Node(id='Physiological Processes', type='Concept', properties={}), Node(id='Neurobiological Processes', type='Concept', properties={}), Node(id='Cognitive Functions', type='Concept', properties={}), Node(id='Perception', type='Concept', properties={}), Node(id='Cognition', type='Concept', properties={}), Node(id='Attention', type='Concept', properties={}), Node(id='Emotion', type='Concept', properties={}), Node(id='Intelligence', type='Concept', properties={}), Node(id='Subjective Experiences', type='Concept', properties={}), Node(id='Motivation', type='Concept', properties={}), Node(id='Brain Functioning', type='Concept', properties={}), Node(id='Personality', type='Concept', properties={}), Node(id='Interpersonal Relationships', type='Concept', properties={}), Node(id='Psychological Resilience', type='Concept', properties={}), Node(id='Family Resilience', type='Concept', properties={}), Node(id='Unconscious Mind', type='Concept', properties={}), Node(id='Research Psychologist', type='Profession', properties={}), Node(id='Psychosocial Variables', type='Concept', properties={}), Node(id='Clinical Psychologist', type='Profession', properties={}), Node(id='Counseling Psychologist', type='Profession', properties={}), Node(id='Symbolic Interpretation', type='Concept', properties={}), Node(id='Mental Health', type='Concept', properties={}), Node(id='Psychotherapy', type='Concept', properties={}), Node(id='Academic Settings', type='Location', properties={}), Node(id='Industrial Settings', type='Location', properties={}), Node(id='Organizational Settings', type='Location', properties={}), Node(id='Human Development', type='Concept', properties={}), Node(id='Aging', type='Concept', properties={}), Node(id='Sports', type='Concept', properties={}), Node(id='Health', type='Concept', properties={}), Node(id='Forensic Science', type='Concept', properties={}), Node(id='Education', type='Concept', properties={}), Node(id='Media', type='Concept', properties={}), Node(id='Psyche', type='Concept', properties={}), Node(id='-Logia', type='Concept', properties={}), Node(id='Marko Marulic', type='Person', properties={}), Node(id='Steven Blankaart', type='Person', properties={}), Node(id='William James', type='Person', properties={}), Node(id='John B. Watson', type='Person', properties={}), Node(id='Folk Psychology', type='Concept', properties={})]\n",
            "Relationships:[Relationship(source=Node(id='Psychology', type='Discipline', properties={}), target=Node(id='Mind', type='Concept', properties={}), type='STUDY', properties={}), Relationship(source=Node(id='Psychology', type='Discipline', properties={}), target=Node(id='Behavior', type='Concept', properties={}), type='STUDY', properties={}), Relationship(source=Node(id='Psychology', type='Discipline', properties={}), target=Node(id='Human', type='Species', properties={}), type='STUDY', properties={}), Relationship(source=Node(id='Psychology', type='Discipline', properties={}), target=Node(id='Nonhuman', type='Species', properties={}), type='STUDY', properties={}), Relationship(source=Node(id='Psychology', type='Discipline', properties={}), target=Node(id='Conscious Phenomena', type='Concept', properties={}), type='STUDY', properties={}), Relationship(source=Node(id='Psychology', type='Discipline', properties={}), target=Node(id='Unconscious Phenomena', type='Concept', properties={}), type='STUDY', properties={}), Relationship(source=Node(id='Psychology', type='Discipline', properties={}), target=Node(id='Mental Processes', type='Concept', properties={}), type='STUDY', properties={}), Relationship(source=Node(id='Mental Processes', type='Concept', properties={}), target=Node(id='Thoughts', type='Concept', properties={}), type='INCLUDES', properties={}), Relationship(source=Node(id='Mental Processes', type='Concept', properties={}), target=Node(id='Feelings', type='Concept', properties={}), type='INCLUDES', properties={}), Relationship(source=Node(id='Mental Processes', type='Concept', properties={}), target=Node(id='Motives', type='Concept', properties={}), type='INCLUDES', properties={}), Relationship(source=Node(id='Biological Psychologists', type='Group', properties={}), target=Node(id='Neuroscience', type='Discipline', properties={}), type='LINK', properties={}), Relationship(source=Node(id='Psychologists', type='Group', properties={}), target=Node(id='Individual', type='Entity', properties={}), type='STUDY', properties={}), Relationship(source=Node(id='Psychologists', type='Group', properties={}), target=Node(id='Group', type='Entity', properties={}), type='STUDY', properties={}), Relationship(source=Node(id='Psychologist', type='Profession', properties={}), target=Node(id='Behavioral Scientist', type='Profession', properties={}), type='CAN_BE', properties={}), Relationship(source=Node(id='Psychologist', type='Profession', properties={}), target=Node(id='Cognitive Scientist', type='Profession', properties={}), type='CAN_BE', properties={}), Relationship(source=Node(id='Psychologists', type='Group', properties={}), target=Node(id='Mental Functions', type='Concept', properties={}), type='STUDY', properties={}), Relationship(source=Node(id='Psychologists', type='Group', properties={}), target=Node(id='Social Behavior', type='Concept', properties={}), type='STUDY', properties={}), Relationship(source=Node(id='Psychologists', type='Group', properties={}), target=Node(id='Physiological Processes', type='Concept', properties={}), type='STUDY', properties={}), Relationship(source=Node(id='Psychologists', type='Group', properties={}), target=Node(id='Neurobiological Processes', type='Concept', properties={}), type='STUDY', properties={}), Relationship(source=Node(id='Psychologists', type='Group', properties={}), target=Node(id='Cognitive Functions', type='Concept', properties={}), type='STUDY', properties={}), Relationship(source=Node(id='Psychologists', type='Group', properties={}), target=Node(id='Perception', type='Concept', properties={}), type='STUDY', properties={}), Relationship(source=Node(id='Psychologists', type='Group', properties={}), target=Node(id='Cognition', type='Concept', properties={}), type='STUDY', properties={}), Relationship(source=Node(id='Psychologists', type='Group', properties={}), target=Node(id='Attention', type='Concept', properties={}), type='STUDY', properties={}), Relationship(source=Node(id='Psychologists', type='Group', properties={}), target=Node(id='Emotion', type='Concept', properties={}), type='STUDY', properties={}), Relationship(source=Node(id='Psychologists', type='Group', properties={}), target=Node(id='Intelligence', type='Concept', properties={}), type='STUDY', properties={}), Relationship(source=Node(id='Psychologists', type='Group', properties={}), target=Node(id='Subjective Experiences', type='Concept', properties={}), type='STUDY', properties={}), Relationship(source=Node(id='Psychologists', type='Group', properties={}), target=Node(id='Motivation', type='Concept', properties={}), type='STUDY', properties={}), Relationship(source=Node(id='Psychologists', type='Group', properties={}), target=Node(id='Brain Functioning', type='Concept', properties={}), type='STUDY', properties={}), Relationship(source=Node(id='Psychologists', type='Group', properties={}), target=Node(id='Personality', type='Concept', properties={}), type='STUDY', properties={}), Relationship(source=Node(id='Psychologists', type='Group', properties={}), target=Node(id='Interpersonal Relationships', type='Concept', properties={}), type='STUDY', properties={}), Relationship(source=Node(id='Psychologists', type='Group', properties={}), target=Node(id='Psychological Resilience', type='Concept', properties={}), type='STUDY', properties={}), Relationship(source=Node(id='Psychologists', type='Group', properties={}), target=Node(id='Family Resilience', type='Concept', properties={}), type='STUDY', properties={}), Relationship(source=Node(id='Psychologists', type='Group', properties={}), target=Node(id='Unconscious Mind', type='Concept', properties={}), type='STUDY', properties={}), Relationship(source=Node(id='Research Psychologist', type='Profession', properties={}), target=Node(id='Psychosocial Variables', type='Concept', properties={}), type='STUDY', properties={}), Relationship(source=Node(id='Clinical Psychologist', type='Profession', properties={}), target=Node(id='Symbolic Interpretation', type='Concept', properties={}), type='USE', properties={}), Relationship(source=Node(id='Counseling Psychologist', type='Profession', properties={}), target=Node(id='Symbolic Interpretation', type='Concept', properties={}), type='USE', properties={}), Relationship(source=Node(id='Psychology', type='Discipline', properties={}), target=Node(id='Mental Health', type='Concept', properties={}), type='APPLICATION', properties={}), Relationship(source=Node(id='Psychology', type='Discipline', properties={}), target=Node(id='Psychotherapy', type='Concept', properties={}), type='APPLICATION', properties={}), Relationship(source=Node(id='Psychologists', type='Group', properties={}), target=Node(id='Academic Settings', type='Location', properties={}), type='WORK', properties={}), Relationship(source=Node(id='Psychologists', type='Group', properties={}), target=Node(id='Industrial Settings', type='Location', properties={}), type='WORK', properties={}), Relationship(source=Node(id='Psychologists', type='Group', properties={}), target=Node(id='Organizational Settings', type='Location', properties={}), type='WORK', properties={}), Relationship(source=Node(id='Psychologists', type='Group', properties={}), target=Node(id='Human Development', type='Concept', properties={}), type='STUDY', properties={}), Relationship(source=Node(id='Psychologists', type='Group', properties={}), target=Node(id='Aging', type='Concept', properties={}), type='STUDY', properties={}), Relationship(source=Node(id='Psychologists', type='Group', properties={}), target=Node(id='Sports', type='Concept', properties={}), type='STUDY', properties={}), Relationship(source=Node(id='Psychologists', type='Group', properties={}), target=Node(id='Health', type='Concept', properties={}), type='STUDY', properties={}), Relationship(source=Node(id='Psychologists', type='Group', properties={}), target=Node(id='Forensic Science', type='Concept', properties={}), type='STUDY', properties={}), Relationship(source=Node(id='Psychologists', type='Group', properties={}), target=Node(id='Education', type='Concept', properties={}), type='STUDY', properties={}), Relationship(source=Node(id='Psychologists', type='Group', properties={}), target=Node(id='Media', type='Concept', properties={}), type='STUDY', properties={}), Relationship(source=Node(id='Psyche', type='Concept', properties={}), target=Node(id='Psychology', type='Discipline', properties={}), type='ETYMOLOGY', properties={}), Relationship(source=Node(id='-Logia', type='Concept', properties={}), target=Node(id='Psychology', type='Discipline', properties={}), type='ETYMOLOGY', properties={}), Relationship(source=Node(id='Marko Marulic', type='Person', properties={}), target=Node(id='Psychology', type='Discipline', properties={}), type='FIRST_USE', properties={}), Relationship(source=Node(id='Steven Blankaart', type='Person', properties={}), target=Node(id='Psychology', type='Discipline', properties={}), type='FIRST_USE_IN_ENGLISH', properties={}), Relationship(source=Node(id='William James', type='Person', properties={}), target=Node(id='Psychology', type='Discipline', properties={}), type='DEFINED', properties={}), Relationship(source=Node(id='John B. Watson', type='Person', properties={}), target=Node(id='Psychology', type='Discipline', properties={}), type='CONTESTED_DEFINITION', properties={}), Relationship(source=Node(id='Folk Psychology', type='Concept', properties={}), target=Node(id='Psychology', type='Discipline', properties={}), type='CONTRAST', properties={})]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will gonna add these nodes and relationships to the repository."
      ],
      "metadata": {
        "id": "IbPY3zL3PzIc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "graph.add_graph_documents(graph_documents_query)"
      ],
      "metadata": {
        "id": "cfk2pdiIPxeX"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RAG APPLICATION"
      ],
      "metadata": {
        "id": "XFhn4nRiP8H-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is the first step to automotize this generation process to the RAG."
      ],
      "metadata": {
        "id": "LR4FAbhGP-3e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade --quiet  langchain langchain-neo4j langchain-openai langchain-experimental neo4j\n",
        "\n",
        "import os\n",
        "from langchain_neo4j import Neo4jGraph\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.chains import GraphCypherQAChain"
      ],
      "metadata": {
        "id": "kqCgwYlEQnxn"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate Neo4jGraph from langchain_neo4j\n",
        "graph = Neo4jGraph(url=os.environ[\"NEO4J_URI\"], username=os.environ[\"NEO4J_USERNAME\"], password=os.environ[\"NEO4J_PASSWORD\"], refresh_schema=False)\n",
        "\n",
        "# Refresh schema before using the graph in the chain\n",
        "graph.refresh_schema()"
      ],
      "metadata": {
        "id": "HV5UMxafQ4-7"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Query the knowledge graph in a RAG application\n",
        "from langchain.chains import GraphCypherQAChain\n",
        "\n",
        "graph.refresh_schema()\n",
        "\n",
        "cypher_chain = GraphCypherQAChain.from_llm(\n",
        "    graph=graph,\n",
        "    cypher_llm=ChatOpenAI(temperature=0, model=\"gpt-4\"),\n",
        "    qa_llm=ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo\"),\n",
        "    validate_cypher=True, # Validate relationship directions\n",
        "    verbose=True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "id": "JITcDEVRPWn0",
        "outputId": "fe941fec-3ae5-4a9c-b8c9-de2cbc167c44"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValidationError",
          "evalue": "1 validation error for GraphCypherQAChain\ngraph\n  Input should be an instance of GraphStore [type=is_instance_of, input_value=<langchain_neo4j.graphs.n...bject at 0x7c130d023340>, input_type=Neo4jGraph]\n    For further information visit https://errors.pydantic.dev/2.10/v/is_instance_of",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-48e89f981fc8>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh_schema\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m cypher_chain = GraphCypherQAChain.from_llm(\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mgraph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mcypher_llm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mChatOpenAI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gpt-4\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_community/chains/graph_qa/cypher.py\u001b[0m in \u001b[0;36mfrom_llm\u001b[0;34m(cls, llm, qa_prompt, cypher_prompt, cypher_llm, qa_llm, exclude_types, include_types, validate_cypher, qa_llm_kwargs, cypher_llm_kwargs, use_function_response, function_response_system, **kwargs)\u001b[0m\n\u001b[1;32m    345\u001b[0m             \u001b[0mcypher_query_corrector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCypherQueryCorrector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorrector_schema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m         return cls(\n\u001b[0m\u001b[1;32m    348\u001b[0m             \u001b[0mgraph_schema\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgraph_schema\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m             \u001b[0mqa_chain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mqa_chain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py\u001b[0m in \u001b[0;36mwarn_if_direct_instance\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                         \u001b[0mwarned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                         \u001b[0memit_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 obj.__init__ = functools.wraps(obj.__init__)(  # type: ignore[misc]\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_community/chains/graph_qa/cypher.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0;34m\"\"\"Initialize the chain.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallow_dangerous_requests\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/load/serializable.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0;34m\"\"\"\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pydantic/main.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, **data)\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0;31m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0m__tracebackhide__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0mvalidated_self\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__pydantic_validator__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself_instance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvalidated_self\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m             warnings.warn(\n",
            "\u001b[0;31mValidationError\u001b[0m: 1 validation error for GraphCypherQAChain\ngraph\n  Input should be an instance of GraphStore [type=is_instance_of, input_value=<langchain_neo4j.graphs.n...bject at 0x7c130d023340>, input_type=Neo4jGraph]\n    For further information visit https://errors.pydantic.dev/2.10/v/is_instance_of"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cypher_chain.invoke({\"query\": \"Who has pychology degree?\"})"
      ],
      "metadata": {
        "id": "XVXJJ58nOzwn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DBPEDIA Integration"
      ],
      "metadata": {
        "id": "A5JQ0DCnR9WY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we are extracting DBpedia information. We do not change the query results yet but it could be a good example to validate LLM in this regard."
      ],
      "metadata": {
        "id": "DjksLms7SALY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rdflib"
      ],
      "metadata": {
        "id": "hETEr2JcSkdz",
        "outputId": "614762e5-20e5-43da-9cd1-6bcdb707a061",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rdflib\n",
            "  Downloading rdflib-7.1.1-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting isodate<1.0.0,>=0.7.2 (from rdflib)\n",
            "  Downloading isodate-0.7.2-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: pyparsing<4,>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from rdflib) (3.2.1)\n",
            "Downloading rdflib-7.1.1-py3-none-any.whl (562 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/562.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m481.3/562.4 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m562.4/562.4 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading isodate-0.7.2-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: isodate, rdflib\n",
            "Successfully installed isodate-0.7.2 rdflib-7.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.graphs import RdfGraph\n",
        "from langchain.chains import GraphSparqlQAChain"
      ],
      "metadata": {
        "id": "hN4PSS6hSeG8"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph = RdfGraph(query_endpoint=\"https://dbpedia.org/sparql\")"
      ],
      "metadata": {
        "id": "HFa-hgCRSRnQ"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dbpedia_chainGPT3point5 = GraphSparqlQAChain.from_llm(\n",
        "    ChatOpenAI(model=\"gpt-3.5-turbo-1106\",\n",
        "               temperature=0,\n",
        "               verbose=True),\n",
        "    graph=graph,\n",
        "    verbose=True,\n",
        "    allow_dangerous_requests=True # Added allow_dangerous_requests=True\n",
        ")\n",
        "dbpedia_chainGPT4 = GraphSparqlQAChain.from_llm(\n",
        "    ChatOpenAI(model=\"gpt-4\",\n",
        "               temperature=0,\n",
        "               verbose=True),\n",
        "    graph=graph,\n",
        "    verbose=True,\n",
        "    allow_dangerous_requests=True # Added allow_dangerous_requests=True\n",
        ")\n",
        "dbpedia_chainGPT4Turbo = GraphSparqlQAChain.from_llm(\n",
        "    ChatOpenAI(model=\"gpt-4-turbo\",\n",
        "               temperature=0,\n",
        "               verbose=True),\n",
        "    graph=graph,\n",
        "    verbose=True,\n",
        "    allow_dangerous_requests=True # Added allow_dangerous_requests=True\n",
        ")"
      ],
      "metadata": {
        "id": "JMAN6ed3SvYY"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"\"\"\n",
        "Relevant DBpedia Knowledge Graph relationship types (relations):\n",
        "  ?movie rdf:type dbo:Film .\n",
        "  ?movie dbo:director dbr:?name .\n",
        "  FILTER regex(?name,<input director's name>)\n",
        "\n",
        "Associated namespaces:\n",
        " dbr:  <http://dbpedia.org/resource/>\n",
        " dbo:  <http://dbpedia.org/ontology/>\n",
        " rdf:  <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
        "\n",
        "List movies by Spike Lee\n",
        "\"\"\"\n",
        "\n",
        "res3point5 = dbpedia_chainGPT3point5.invoke({dbpedia_chainGPT3point5.input_key: query})[dbpedia_chainGPT3point5.output_key]\n",
        "print(res3point5)\n",
        "\n",
        "res4 = dbpedia_chainGPT4.invoke({dbpedia_chainGPT4.input_key: query})[dbpedia_chainGPT4.output_key]\n",
        "\n",
        "print(res4)\n",
        "\n",
        "res4plus = dbpedia_chainGPT4Turbo.invoke({dbpedia_chainGPT4Turbo.input_key: query})[dbpedia_chainGPT4Turbo.output_key]\n",
        "\n",
        "print(res4plus)\n"
      ],
      "metadata": {
        "id": "YvQW-aWzTD7_",
        "outputId": "77f93dc6-73c0-4c8b-c504-753e3b2f5df4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 883
        }
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new GraphSparqlQAChain chain...\u001b[0m\n",
            "Identified intent:\n",
            "\u001b[32;1m\u001b[1;3mSELECT\u001b[0m\n",
            "Generated SPARQL:\n",
            "\u001b[32;1m\u001b[1;3m```\n",
            "PREFIX dbr: <http://dbpedia.org/resource/>\n",
            "PREFIX dbo: <http://dbpedia.org/ontology/>\n",
            "PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
            "SELECT ?movie\n",
            "WHERE {\n",
            "    ?movie rdf:type dbo:Film .\n",
            "    ?movie dbo:director dbr:Spike_Lee .\n",
            "}\n",
            "```\u001b[0m\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "You did something wrong formulating either the URI or your SPARQL query",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/rdflib/plugins/stores/sparqlconnector.py\u001b[0m in \u001b[0;36mquery\u001b[0;34m(self, query, default_graph, named_graph)\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                 res = urlopen(\n\u001b[0m\u001b[1;32m    114\u001b[0m                     \u001b[0mRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery_endpoint\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mqsa\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"headers\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    524\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m             response = self.parent.error(\n\u001b[0m\u001b[1;32m    635\u001b[0m                 'http', request, response, code, msg, hdrs)\n",
            "\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    562\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'default'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'http_error_default'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36mhttp_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    642\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 400: Bad Request",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-56-d4d94642293c>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \"\"\"\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mres3point5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdbpedia_chainGPT3point5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mdbpedia_chainGPT3point5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_key\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdbpedia_chainGPT3point5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres3point5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m         \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m             outputs = (\n\u001b[0;32m--> 160\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m                 \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_community/chains/graph_qa/sparql.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mintent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"SELECT\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m             \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerated_sparql\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m             \u001b[0m_run_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Full Context:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_community/graphs/rdf_graph.py\u001b[0m in \u001b[0;36mquery\u001b[0;34m(self, query)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mParserError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Generated SPARQL statement is invalid\\n\"\u001b[0m \u001b[0;34mf\"{e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/rdflib/graph.py\u001b[0m in \u001b[0;36mquery\u001b[0;34m(self, query_object, processor, result, initNs, initBindings, use_store_provided, **kwargs)\u001b[0m\n\u001b[1;32m   1563\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"query\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0muse_store_provided\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1565\u001b[0;31m                 return self.store.query(\n\u001b[0m\u001b[1;32m   1566\u001b[0m                     \u001b[0mquery_object\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1567\u001b[0m                     \u001b[0minitNs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/rdflib/plugins/stores/sparqlstore.py\u001b[0m in \u001b[0;36mquery\u001b[0;34m(self, query, initNs, initBindings, queryGraph, DEBUG)\u001b[0m\n\u001b[1;32m    244\u001b[0m             )\n\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m         return self._query(\n\u001b[0m\u001b[1;32m    247\u001b[0m             \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mqueryGraph\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_contextual\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqueryGraph\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/rdflib/plugins/stores/sparqlstore.py\u001b[0m in \u001b[0;36m_query\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_queries\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSPARQLStore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_inject_prefixes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra_bindings\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mMapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/rdflib/plugins/stores/sparqlconnector.py\u001b[0m in \u001b[0;36mquery\u001b[0;34m(self, query, default_graph, named_graph)\u001b[0m\n\u001b[1;32m    115\u001b[0m                 )\n\u001b[1;32m    116\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# noqa: F841\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m    118\u001b[0m                     \u001b[0;34m\"You did something wrong formulating either the URI or your SPARQL query\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m                 )\n",
            "\u001b[0;31mValueError\u001b[0m: You did something wrong formulating either the URI or your SPARQL query"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}